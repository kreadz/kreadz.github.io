# 目录
1. VulDeePecker (NDSS'18)
2. μVulDeePecker (IEEE Transactions on Dependable and Secure Computing)

## **0x01** Database of "VulDeePecker: A Deep Learning-Based System for Vulnerability Detection" (NDSS'18)

代码小工具数据库（CGD）主要针对C/C++程序中的两类漏洞，缓冲区错误漏洞（CWE-119）和资源管理错误漏洞（CWE-399）。每个代码小工具都由多个程序语句（即代码行）组成，这些语句根据与某些库/API 函数调用的参数关联的数据流相互关联。

基于美国国家漏洞数据库（NVD）和NIST软件保障参考数据集（SARD）项目，我们收集了520个开源软件程序文件及其对应的diff文件和8122个buffer错误漏洞测试用例，以及320个开源软件程序文件及其相应的diff文件和1729个资源管理错误漏洞测试用例。

CGD 数据库总共包含 61,638 个代码小工具，其中包括 17,725 个易受攻击的代码小工具和 43,913 个不易受攻击的代码小工具。在 17,725 个易受攻击的代码小工具中，10,440 个对应缓冲区错误漏洞，其余 7,285 个对应资源管理错误漏洞。

### 系统设计
VulDeePecker总览:

![](https://img-blog.csdnimg.cn/img_convert/dcc633955fa94fd850ad538adae986e4.png)

将训练集源码转化为code gadget代码集合，然后标记样本，将样本转化为可处理的特征向量，输入特征向量到BLSTM网络（fine-tune）中，得到模型参数后对测试集进行测试，判断程序是否存在漏洞。

#### 1. 生成code gadget
**code gadget**：基于启发式方法构建的代码语句集合，代码语句间存在一定的语义联系（数据流或控制流上的联系）；

> code gadget：函数调用语句和其参数相关的数据依赖和控制依赖语句

**启发式方法**：本文用程序的一些关键的元素（key point），如API调用，数组变量，指针变量等表征程序是否存在漏洞。比如有的漏洞是因为系统api调用，那么key point就是该api，通过把同该key point具有联系的代码语句组合起来形成相应的code gadget；


![](https://img-blog.csdnimg.cn/img_convert/06358157744037a4c23f43e4953f27a8.png)

#### 2. 标注样本
根据NVD和SARD漏洞库进行样本标注：

![](https://img-blog.csdnimg.cn/img_convert/a742e6ca40b917c77b54bb423ab6b2d5.png)

#### 3. 将code gadgets编码为固定长向量
![](https://img-blog.csdnimg.cn/img_convert/98b86d6ef1c0a3153efadfba467f5c4b.png)

先转化为符号表示，然后在利用句法分析建立词表，再用word2vec模型进行向量编码。

**代码小工具 -> Vector**

代码小工具：不一定连续的代码行，在语义上彼此相关（**代码片段**）

> Word2Vec是语言模型中的一种，它是从大量文本预料中以无监督方式学习语义知识的模型，被广泛地应用于自然语言处理中。<br>Word2Vec是用来生成词向量的工具，而词向量与语言模型有着密切的关系。

#### 4. 模型训练
将向量输入blstm网络，进行模型训练，得到训练参数，用于测试

![](https://img-blog.csdnimg.cn/img_convert/9b54cad0f2a26a6882b9baa799847bc3.png)

### 实验结果
数据集是作者团队开发的一个数据集CGD(cwe339,cwe119,两类漏洞，缓冲区溢出和资源管理漏洞)，具体见https://github.com/CGCL-codes/VulDeePecker ；

metrics：假负样本率，假正样本率，F值，精确度等。

数据集分为了六个子集用于不同的测试目的：

![](https://img-blog.csdnimg.cn/img_convert/7aa134a8472e5f65a33ecd950bfe0047.png)

结果：

![](https://img-blog.csdnimg.cn/img_convert/bde8def38bbc0373c45a49572bd89092.png)

结论：系统可以识别多种漏洞，但具有数据依赖性 ；

![](https://img-blog.csdnimg.cn/img_convert/aee04a8e132ff568c705c2b1d0e5a1aa.png)

结论：先验知识介入可以增加系统能力 ；

![](https://img-blog.csdnimg.cn/img_convert/cb1d50e8df2d32f7595a07886dadb03d.png)
结论：系统相对于现有（2018）的一些静态检测方法具有显而易见的优势 ；

### 讨论：创新，贡献，不足
**创新与贡献**：

- 首次在漏洞检测上引入深度学习的方法，并且解决了一些存在问题。
- 讨论了一些适用深度学习的面向程序源码的向量编码原则。
- 在实际应用中证明了该深度学习系统一定的有效性 （检测出了几个实际应用中存在的漏洞）
- 给出了一个可用的数据集

**不足**

- 非端到端方法
- 向量编码时使用启发式方法
- 仅面向C/C++源码，且用例漏洞类型太少
- 不是每个软件都开源

### 复现
该论文官方并没有放出源码，但在github上还是有一份他人的复现代码 ，我这就直接拿来用了。值得强调的是，复现的难点不在于模型，而是在于之前的一些预处理工作，所谓的dirty work。说实话，如果面对的是写的琐碎但却细节模糊而且还不放源码的论文，复现的难度太大而且没啥意义。

这个复现代码也存在几个坑，都在blstm.py中，

一个是在建立特征向量的时候，转换了label和feature；这个重写一下就行。

另一个是关于样本类别权重平衡的问题，这个就是tf的锅了，tf的版本迭代的兼容性确实让人头疼。不嫌麻烦的可以根据调试信息改下相应的源码，或者用pytorch重写一个。或者简单点直接把关于样本类别权重平衡的代码注释掉就行了，像本文数据集这样的样本分布，其实也没多偏，影响不了多少精度。事实上，关于样本分布和取样的问题到现在还是一个基础问题，需要做的突破还有很多的。

cwe339:

![](https://img-blog.csdnimg.cn/img_convert/c0719b9e57a316d6192ff1b65d1b3239.png)

cwe119:

![](https://img-blog.csdnimg.cn/img_convert/0bfe779f1c405dd855eb929065adb6c7.png)




### 成果
为了评估 VulDeePecker，我们提出了第一个用于深度学习方法的漏洞数据集。实验结果表明，与其他方法相比，VulDeePecker 可以实现更少的假阴性（具有合理的假阳性）。我们进一步将 VulDeePecker 应用于 3 个软件产品（即 Xen、Seamonkey 和 Libav），并检测到 4 个漏洞，这些漏洞未在国家漏洞数据库中报告，但供应商在发布这些产品的更高版本时“默默”修补;相比之下，我们试验过的其他漏洞检测系统几乎完全忽略了这些漏洞。


## **0x02** μVulDeePecker_A Deep Learning_Based System for Multiclass Vulnerability Detection

基于深度学习的多类型漏洞检测系统 
VulDeePecker


![](https://img-blog.csdnimg.cn/img_convert/8b9e984234ffc175a040761c8b97d2e7.png)

> code attention：R表示漏洞语法规则集合，code attention表示code gadget中与R中某一条规则相匹配的语句的集合
### 1. 生成code gadget
#### μVulDeePecker对VulDeePecker中code gadget的生成方法改进:
VulDeePecker将函数分为前向函数（接受外部输入，例如scanf）和后向函数(不接收外部输入，例如malloc)，对于前向函数只提取前向切片，对于后向函数只提取后向切片，但在 
VulDeePecker中所有的函数都考虑前向切片和后向切片。

scanf()参数是在此函数被调用之前，但如果按照前向函数 只进行前向切片，那么这个切片就会将之前的参数遗漏。malloc()是后向函数，被分配的内存在前向切片使用，但若只进行后向切片就会遗漏内存使用和释放的语句。因此，不对函数类型进行区分，只要是API或者库函数调用，都进行前向和后向切片，可能对漏洞检测更有帮助

图2a为生成strncpy的code gadget的过程，首先生成系统依赖图，然后识别出函数调用语句strncpy，再根据算法1生成code gadget


![](https://img-blog.csdnimg.cn/img_convert/eb118460f138af732b118674458a6922.png)

### 2 给code gadget打标签
无漏洞code gadget标签为0，有漏洞code gadget则根据漏洞类型标为1、2、3...

### 3 code gadget标准化
将自定义变量名和函数名转化为统一格式如varb_0、varb_1，fun_0、fun_1。因为不同的程序员有不同的编码习惯(如格式、变量和函数命名)，这可能会影响多类型漏洞检测模型的能力

![](https://img-blog.csdnimg.cn/img_convert/0f98850a7d23d0ed1d5945eee7e211b1.png)


### 4 提取code attention
对于与 library/API调用相关的漏洞来说，API的使用和其参数都可以导致漏洞的发生。 考虑到数据源检查、数据净化操作检查和library/API函数调用合理性检查会影响漏洞的产生，因此提出以下3个生成attention的语法规则

rule1: 对于定义类型的语句，只要定义的变量是library/API调用的参数，则该句句属于code attention。可判断漏洞是否是由数据源造成的
rule2: code gadgets中的控制语句属于code attention，可判断在library/API调用语句执行之前是否进行了适当的边界检查和安全筛选
rule3: code gadgets中的library/API函数调用语句属于code attention，有助于识别漏洞类型

根据rule1可知2、4、5为code gadget
根据rule2可知7、16为code gadget
根据rule3可知6、8、17为code gadget


![](https://img-blog.csdnimg.cn/img_convert/8cced58e8068ab85560b45758834c39e.png)

### 5 将code gadget和code attention向量化
使用常用的词嵌入技术将二者转化为固定长度的向量，作为神经网络的输入

### 6 构建building-block BLSTM网络
构建的神经网络模型包括三个BLSTM网络，全局特征学习模型通过code gadget提取全局特征，局部特征学习模型通过code attention提取局部特征，之后通过特征融合模型将全局特征和局部特征进行融合，再输入分类器进行分类。
全局特征学习模型和局部特征学习模型的神经网络结构相同，但规模较小，因为code attention的向量长度小。



![](https://img-blog.csdnimg.cn/img_convert/1a032155125ce5f7f4f1e90fcee9ab15.png)
### 7 模型训练
1. 利用开源C/C++代码分析工具Joern构造程序依赖图，根据函数之间的调用关系生成系统依赖图，识别出与安全相关的811种C/C++ library/API函数调用(利用checkmark工具可以得到)之一相匹配的节点，利用算法1生成code gadgets
2. 给code gadgets打标签
3. 利用词法分析程序分析程序语句的token类型和上下文结构，识别出自定义的变量和函数，将自定义变量和函数名标准化
4. 利用算法2提取code attention
5. 利用word2vec的skip-gram模型将code gadgets和code attention转化为固定长度的向量，若向量长度小于指定长度，则在末尾填充0，若向量长度大于指定长度，则删除末尾部分
6. 训练building-block BLSTM神经网络模型，首先训练全局特征模型和局部特征模型，再训练特征融合模型

训练完成后各模型的参数值如下：

![](https://img-blog.csdnimg.cn/img_convert/367643412682083b41868eaa3667c2f8.png)


### 8 结果


![](https://img-blog.csdnimg.cn/img_convert/ab7f591cd9794b0d066b4b479c7e9f13.png)

### 9 VulDeePecker、 VulDeePecker和SySeVR对比
**1. VulDeePecker**

针对库/API调用相关漏洞，只能检测是否有漏洞，不能检测漏洞类型
code gadgets：前向函数生成前向切片，后向函数生成后向切片，前向切片和后向切片合成程序切片，通过程序切片构造code gadgets
生成切片时只考虑数据依赖
若向量长度小于L，针对后向切片得到的向量，在开始部分填充0，否则在向量尾部填充0。若长度大于L，针对后向切片得到的向量，删除其开始部分，否则删除结尾部分。
使用BLSTM神经网络
**2. SySeVR**

检测多种漏洞类型，API/库函数调用、数组使用、指针使用、算术表达式等相关漏洞
引入SyVCs和SeVCs的概念，分别表示漏洞的语法特征和语义特征
利用程序切片技术生成SeVCs，考虑数据依赖和控制依赖
将SeVCs编码成向量，向量长度小于指定长度时，向尾部填充0；向量长度大于指定长度时，并不直接删除尾部，而是去除最左边或最右边一部分保证SyVC处于向量的中间位置
实验表明使用BRGU模型效果更好
仅使用一种模型来检测多种漏洞，即针对每种漏洞分别训练模型
**3. VulDeePecker**

检测与library/API相关的多种漏洞类型
code gadgets：不区分前向函数和后向函数，所有函数都生成前向切片和后向切片，根据程序切片生成code gadgets，表示程序的全局特征
code attention:引入code attention的概念，表示程序的局部特征，利用局部特征帮助检测漏洞类型
生成切片时考虑数据依赖和控制依赖
向量长度小于指定长度时在尾部填充0，大于指定长度时直接删除尾部
引入特征融合概念，将全局特征和局部特征融合，利用building-block BLSTM神经网络学习漏洞特征和检测多种漏洞类型，无需针对每种漏洞分别训练模型